# -*- coding: utf-8 -*-
"""Lab02_NeuralNets_ConvNet_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SZgyvk8C45sIhhPJMu1hPAQc_7iA2ig-

# Neural Nets: Convolution

In this lab we try to build a model to detect handwritten digits. This lab should introduce you in the use of keras and should enable you to build and train your own CNNs.
"""

# Commented out IPython magic to ensure Python compatibility.
# general imports
import torchvision.datasets as datasets
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np

# neural network
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import DataLoader
from torch.optim import Adam


# %matplotlib inline

"""First of all, we load our data set that is divided into a training and a testing set."""

# load digit dataset with training and test images
x_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())
x_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())

"""In this data set we have 10 different classes. Each data point in this data set is an image of resoution 28x28 and shows a handwritten digit."""

nb_classes = 10
# dimension
x_train[0][0].shape

"""To get a better feeling for the data we take a look at the first 10 instances."""

# The data consists of images of digits, let's
# have a look at the first 4 images, stored in the `images` attribute of the
# dataset. For all images, we know which digit they represent: it is given in the 'target' of
# the dataset.
num_to_show = 10
for i in range(num_to_show):
    image = x_train[i][0].numpy().squeeze()
    label = x_train[i][1]
    plt.subplot(2, num_to_show, i + 1)
    plt.axis('off')
    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')
    plt.title(str(label))
plt.show()

# print some statistics
print('number of train images: ' + str(len(x_train)))

"""<b>Exercise 1:</b>  
Create a histogram showing the class distribution.
"""

# YOUR CODE GOES HERE

"""<b>Simple Neural Model</b>

Our first simple model is a neural net with one hidden layer consisting of 512 hidden units and a ReLU activation function. To prevent overfitting a dropout layer is added after that. The input for this net is an image that is converted to a flat vector in the first layer. Please have a look at the architecture and try to understand the structure of this neural net.
"""

# weights initialization for Linear layers
def init_weights(m):
    if isinstance(m, nn.Linear):
        torch.nn.init.xavier_uniform_(m.weight)
        m.bias.data.fill_(0.01)

class SimpleModel(nn.Module):
    def __init__(self, input_dim=784, nb_classes=10):
        super().__init__()
        self.layers = nn.Sequential(nn.Linear(input_dim, 512),
                                   nn.ReLU(),
                                   nn.Dropout(p=0.2),
                                   nn.Linear(512, nb_classes))
        self.layers.apply(init_weights) #pytorch weight initialization is poor by default
    def forward(self, x):
        return self.layers(torch.flatten(x, start_dim=1))
simple_model = SimpleModel()
print(simple_model)

"""<b>Simple Convolutional Neural Net</b>

The second neural net we are using is a convolutional neural net. This network consists of a convolutional layer, a max pooling layer and a dense layer in the end.
"""

class CNNModel(nn.Module):
    def __init__(self,
                 nb_filters_one = 32,
                 nb_conv = 3,
                 nb_pool = 2,
                 dense_size = 128,
                 nb_classes = 10):
        super().__init__()
        self.conv = nn.Sequential(nn.Conv2d(1, nb_filters_one, kernel_size=nb_conv, padding='same'),
                                  nn.ReLU(),
                                  nn.MaxPool2d(kernel_size=nb_pool),
                                  nn.Dropout(p=0.25))
        self.dense = nn.Sequential(nn.Linear(28*28*nb_filters_one//(nb_pool**2), dense_size), #dummy
                                  nn.Dropout(p=0.25),
                                  nn.Linear(dense_size, nb_classes))

        self.apply(init_weights) #pytorch weight initialization is poor by default
    def forward(self, x):
        return self.dense(torch.flatten(self.conv(x), start_dim=1))

cnn_model = CNNModel()
print(cnn_model)

def train_epoch(model, dataloader, loss_fn, device, optim):
    losses = []
    model.train()
    loss_ = loss_fn()
    accs = []
    for batch in dataloader:
    	optim.zero_grad()
        input_features = batch[0].to(device)
        target = F.one_hot(batch[1], 10).to(device)
        logits = model(input_features)
        bce = loss_(logits, target.float()) # compute the loss
        bce.backward() # backpropagate and calculate gradients wrt loss
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1) #Clip gradients to avoid large gradients
        optim.step() # update model parameters
        losses.append(bce.detach().cpu().item()) # transform loss to scalar
        predicted_classes = logits.argmax(axis=1)
        observed_classes = target.argmax(axis=1)
        equal_classes = predicted_classes == observed_classes
        accuracy = equal_classes.sum()/equal_classes.shape[0]
        accs.append(accuracy.detach().cpu().item()) #note the computation is not strictly accurate, batch sizes can be different
    return np.mean(losses), np.mean(accs)

def test_epoch(model, dataloader,loss_fn, device):
    losses = []
    model.eval() # set the model in evaluation mode
    loss_ = loss_fn()
    accs = []
    with torch.no_grad(): # Do not compute the gradients
        for batch in dataloader:
            input_features = batch[0].to(device)
            target = F.one_hot(batch[1], 10).to(device)
            logits = model(input_features)
            bce = loss_(logits, target.float()) # compute the loss
            losses.append(bce.detach().cpu().item())
            predicted_classes = logits.argmax(axis=1)
            observed_classes = target.argmax(axis=1)
            equal_classes = predicted_classes == observed_classes
            accuracy = equal_classes.sum()/equal_classes.shape[0]
            accs.append(accuracy.detach().cpu().item()) #note the computation is not strictly accurate, batch sizes can be different
    return np.mean(losses), np.mean(accs)

"""<b>Exercise 2:</b>  
Compare the two different network architectures. What can you say about the number of trainable parameters? Which neural net will probably work better?

<b>Your answer:</b>

Now we can train both models and save the training and testing accuracies for the different epochs in two lists. This can really take some time.


(**Advanced**: You may install the gpu packages of pytorch to reduce calculation time)
"""

batch_size = 128
numEpochs = 10
loss_fn = nn.BCEWithLogitsLoss
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # use GPU if available
train_dataloader = DataLoader(x_train, batch_size = batch_size, shuffle = True)
test_dataloader = DataLoader(x_test, batch_size = batch_size, shuffle = True)

simple_model = SimpleModel()
optim = Adam(simple_model.parameters(), lr=0.0001) # optimizer
simple_model.to(device) # move weights to device, needed if GPU
train_accs_simple = []
test_accs_simple = []
for epoch in range(numEpochs): # train model
    train_loss = train_epoch(simple_model, train_dataloader, loss_fn, device, optim)
    test_loss = test_epoch(simple_model, test_dataloader, loss_fn, device)
    train_accs_simple.append(train_loss[1])
    test_accs_simple.append(test_loss[1])
    print(f"epoch: {epoch + 1}/{numEpochs}, train_accuracy: {train_loss[1]}, test_accuracy: {test_loss[1]}")

cnn_model = CNNModel()
optim = Adam(cnn_model.parameters(), lr=0.0001)

cnn_model.to(device)
train_accs_cnn = []
test_accs_cnn = []
for epoch in range(numEpochs): #train model
    train_loss = train_epoch(cnn_model, train_dataloader, loss_fn, device, optim)
    test_loss = test_epoch(cnn_model, test_dataloader, loss_fn, device)
    train_accs_cnn.append(train_loss[1])
    test_accs_cnn.append(test_loss[1])
    print(f"epoch: {epoch + 1}/{numEpochs}, train_accuracy: {train_loss[1]}, test_accuracy: {test_loss[1]}")

"""<b>Exercise 3:</b>  
Plot the learning curves (training loss and validation loss) for the two neural nets, showing the training and testing loss over the number of epochs. What are the learning curves telling you?
"""

# YOUR CODE GOES HERE

"""<b>Excercise 4:</b>

Normalize the input data so that all values are between 0 and 1. After that, retrain the simple model. Are the results better? Can you explain the results?

suggestion:
use torchvision.transforms.Normalize(), transforms can be composed using transforms.Compose
"""

# calculate the mean and std in training data
mean = 0.
std = 0.
for images, _ in train_dataloader:
    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)
    images = images.view(batch_samples, images.size(1), -1)
    mean += images.mean(2).sum(0)
    std += images.std(2).sum(0)

mean /= len(train_dataloader.dataset)
std /= len(train_dataloader.dataset)

# normalize images
transform_list = [] # REPLACE BY NORMALIZER
x_train_normalized = datasets.MNIST(root='./data', train=True, download=True, transform=transform_list)
x_test_normalized = datasets.MNIST(root='./data', train=False, download=True, transform=transform_list)

train_dataloader_normalized = DataLoader(x_train_normalized, batch_size = batch_size, shuffle = True)
test_dataloader_normalized = DataLoader(x_test_normalized, batch_size = batch_size, shuffle = True)
# retrain model
simple_model = SimpleModel()
optim = Adam(simple_model.parameters(), lr=0.0001)
simple_model.to(device)
train_accs_simple = []
test_accs_simple = []
for epoch in range(numEpochs):
    train_loss = train_epoch(simple_model, train_dataloader_normalized, loss_fn, device, optim)
    test_loss = test_epoch(simple_model, train_dataloader_normalized, loss_fn, device)
    train_accs_simple.append(train_loss[1])
    test_accs_simple.append(test_loss[1])
    print(f"epoch: {epoch + 1}/{numEpochs}, train_accuracy: {train_loss[1]}, test_accuracy: {test_loss[1]}")

"""<b>Excercise 5:</b>
    
Write a Transform that randomly places the digits from the input data on a 2-dimensional image of size 28x28. Do this by firstly resizing the image to the size 14x14 and than placing this digit on a grid of 28x28. After that the data set should look like shown in the image above.
<img src="./non-centered.png" width=600 height=600\>
"""

class RandomNoise(object):
    """Crop randomly the image in a sample.

    Args:
        output_size (tuple or int): Desired output size. If int, square crop
            is made.
    """

    def __init__(self, size, scale_percent=50):
        assert isinstance(size, (int, tuple))
        if isinstance(size, int):
            self.size = (size, size)
        else:
            assert len(size) == 2
            self.size = size
        self.res_width = int(size[0] * scale_percent // 100)
        self.res_height = int(size[1] * scale_percent // 100)
        self.resize = transforms.Resize([self.res_width, self.res_height]) #Resizes the image

    def __call__(self, image):
        resized_img = self.resize(image).squeeze()
        new_image = torch.zeros(self.size)
        # YOUR CODE GOES HERE
        return new_image.unsqueeze(0)

"""Now we can have a look at the new data set of non-centered digits.


"""

# try to create a more realistic data set
transform_list = transforms.Compose([transforms.ToTensor(), RandomNoise((28, 28), 50)])
x_train_noise = datasets.MNIST(root='./data', train=True, download=True, transform=transform_list)
x_test_noise = datasets.MNIST(root='./data', train=False, download=True, transform=transform_list)

for i in range(50):
    image = x_train_noise[i][0].squeeze()
    label = x_train_noise[i][1]
    plt.subplot(5, 10, i + 1)
    plt.axis('off')
    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')
    plt.title(label)
plt.show()

"""<b>Excercise 6:</b>
    
Train the simple NN and the CNN on this new data set for 10 epochs and compare the training and testing results with each other.

What conclusions can you draw?
"""

train_dataloader_noise = DataLoader(x_train_noise, batch_size = batch_size, shuffle = True)
test_dataloader_noise = DataLoader(x_test_noise, batch_size = batch_size, shuffle = True)

simple_model = SimpleModel()
optim = Adam(simple_model.parameters(), lr=0.0001)
simple_model.to(device)
train_accs_simple = []
test_accs_simple = []
# YOUR CODE GOES HERE

cnn_model = CNNModel()
optim = Adam(cnn_model.parameters(), lr=0.0001)

cnn_model.to(device)
train_accs_cnn = []
test_accs_cnn = []
# YOUR CODE GOES HERE

"""<b>Additional Excercise</b>

Try to build a model that is able to get better classification results on the non-centered data set.
"""

# YOUR CODE GOES HERE
